# LLM API Configuration
# 基础配置（单个provider）
LLM_API_KEY=your_openai_api_key_here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-3.5-turbo
LLM_MAX_TOKENS=1000
LLM_TEMPERATURE=0.1
LLM_TIMEOUT=30

# 多Provider轮询配置（可选，用于避免速率限制）
# Provider 1
LLM_PROVIDER_1_API_KEY=your_openai_api_key_here
LLM_PROVIDER_1_BASE_URL=https://api.openai.com/v1
LLM_PROVIDER_1_MODEL=gpt-3.5-turbo
LLM_PROVIDER_1_MAX_TOKENS=1000
LLM_PROVIDER_1_TEMPERATURE=0.1
LLM_PROVIDER_1_WEIGHT=1
LLM_PROVIDER_1_TIMEOUT=30

# Provider 2
LLM_PROVIDER_2_API_KEY=your_second_api_key_here
LLM_PROVIDER_2_BASE_URL=https://api.openai.com/v1
LLM_PROVIDER_2_MODEL=gpt-4-turbo-preview
LLM_PROVIDER_2_MAX_TOKENS=2000
LLM_PROVIDER_2_TEMPERATURE=0.1
LLM_PROVIDER_2_WEIGHT=2
LLM_PROVIDER_2_TIMEOUT=45

# Provider 3（示例：使用其他OpenAI兼容的服务）
LLM_PROVIDER_3_API_KEY=your_deepseek_api_key_here
LLM_PROVIDER_3_BASE_URL=https://api.deepseek.com/v1
LLM_PROVIDER_3_MODEL=deepseek-chat
LLM_PROVIDER_3_MAX_TOKENS=1500
LLM_PROVIDER_3_TEMPERATURE=0.1
LLM_PROVIDER_3_WEIGHT=1
LLM_PROVIDER_3_TIMEOUT=30

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_neo4j_password_here

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=logs/app.log

# Processing Configuration
BATCH_SIZE=50
MAX_WORKERS=4
PROCESSING_TIMEOUT=300

# Data Paths
INPUT_DATA_PATH=data/input
OUTPUT_DATA_PATH=data/output
CACHE_PATH=data/cache