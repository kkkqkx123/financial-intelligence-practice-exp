#!/usr/bin/env python3
"""
æµ‹è¯•æ–°çš„OpenAIå®¢æˆ·ç«¯å’Œè½®è¯¢æ± åŠŸèƒ½
"""

import os
import sys
import json
import time
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.processors import get_llm_client, get_llm_processor, get_batch_llm_processor, PollingPool, OpenAICompatibleClient
from src.processors.llm_client import OpenAICompatibleClient, PollingPool

def test_single_client():
    """æµ‹è¯•å•ä¸ªOpenAIå®¢æˆ·ç«¯"""
    print("=== æµ‹è¯•å•ä¸ªOpenAIå®¢æˆ·ç«¯ ===")
    
    try:
        # è·å–LLMå®¢æˆ·ç«¯
        client = get_llm_client()
        print(f"å®¢æˆ·ç«¯ç±»å‹: {type(client).__name__}")
        
        # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
        print("\n1. æµ‹è¯•åŸºæœ¬æ–‡æœ¬ç”Ÿæˆ...")
        test_prompt = "è¯·ç”¨ä¸€å¥è¯ä»‹ç»äººå·¥æ™ºèƒ½åœ¨é‡‘èé¢†åŸŸçš„åº”ç”¨ã€‚"
        response = client.generate_response(test_prompt)
        print(f"å“åº”: {response}")
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        stats = client.get_stats()
        print(f"\nå®¢æˆ·ç«¯ç»Ÿè®¡: {json.dumps(stats, ensure_ascii=False, indent=2)}")
        
    except Exception as e:
        print(f"å•ä¸ªå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def test_polling_pool():
    """æµ‹è¯•è½®è¯¢æ± """
    print("\n=== æµ‹è¯•è½®è¯¢æ±  ===")
    
    try:
        # åˆ›å»ºè½®è¯¢æ± 
        pool = PollingPool()
        print(f"è½®è¯¢æ± ä¸­çš„provideræ•°é‡: {len(pool.providers)}")
        
        # æµ‹è¯•è½®è¯¢åŠŸèƒ½
        print("\n2. æµ‹è¯•è½®è¯¢æ± æ–‡æœ¬ç”Ÿæˆ...")
        test_prompt = "è¯·ç”¨ä¸€å¥è¯ä»‹ç»åŒºå—é“¾æŠ€æœ¯ã€‚"
        
        for i in range(3):
            print(f"\nç¬¬{i+1}æ¬¡è°ƒç”¨:")
            response = pool.generate_response(test_prompt)
            print(f"å“åº”: {response}")
            
            # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„provider
            if pool.providers:
                current_provider = pool.providers[pool.current_index - 1] if pool.current_index > 0 else pool.providers[-1]
                print(f"ä½¿ç”¨çš„provider: {current_provider.get('name', 'Unknown')}")
            else:
                print(f"ä½¿ç”¨çš„provider: æ¨¡æ‹Ÿå®¢æˆ·ç«¯ (æ— é…ç½®provider)")
            
            time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿ
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        stats = pool.get_stats()
        print(f"\nè½®è¯¢æ± ç»Ÿè®¡: {json.dumps(stats, ensure_ascii=False, indent=2)}")
        
    except Exception as e:
        print(f"è½®è¯¢æ± æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def test_llm_processor():
    """æµ‹è¯•LLMå¤„ç†å™¨"""
    print("\n=== æµ‹è¯•LLMå¤„ç†å™¨ ===")
    
    try:
        # è·å–LLMå¤„ç†å™¨
        processor = get_llm_processor()
        print(f"å¤„ç†å™¨ç±»å‹: {type(processor).__name__}")
        
        # æµ‹è¯•å®ä½“æè¿°å¢å¼º
        print("\n3. æµ‹è¯•å®ä½“æè¿°å¢å¼º...")
        entity_name = "è…¾è®¯ç§‘æŠ€"
        context = {
            "industry": "äº’è”ç½‘",
            "founded_year": 1998,
            "location": "æ·±åœ³"
        }
        
        enhanced_description = processor.enhance_entity_description(entity_name, context)
        print(f"å¢å¼ºåçš„æè¿°: {enhanced_description}")
        
        # æµ‹è¯•å†²çªè§£å†³
        print("\n4. æµ‹è¯•å®ä½“å†²çªè§£å†³...")
        conflict_group = [
            {"name": "é˜¿é‡Œå·´å·´", "description": "ç”µå•†å·¨å¤´"},
            {"name": "é˜¿é‡Œé›†å›¢", "description": "ç”µå•†å·¨å¤´"}
        ]
        
        resolution = processor.resolve_entity_conflicts(conflict_group)
        print(f"å†²çªè§£å†³ç»“æœ: {json.dumps(resolution, ensure_ascii=False, indent=2)}")
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        stats = processor.get_stats()
        print(f"\nå¤„ç†å™¨ç»Ÿè®¡: {json.dumps(stats, ensure_ascii=False, indent=2)}")
        
    except Exception as e:
        print(f"LLMå¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def test_batch_processor():
    """æµ‹è¯•æ‰¹é‡å¤„ç†å™¨"""
    print("\n=== æµ‹è¯•æ‰¹é‡å¤„ç†å™¨ ===")
    
    try:
        # è·å–æ‰¹é‡LLMå¤„ç†å™¨
        batch_processor = get_batch_llm_processor()
        print(f"æ‰¹é‡å¤„ç†å™¨ç±»å‹: {type(batch_processor).__name__}")
        
        # æµ‹è¯•æ‰¹é‡å®ä½“æè¿°å¢å¼º
        print("\n5. æµ‹è¯•æ‰¹é‡å®ä½“æè¿°å¢å¼º...")
        entities = [
            {"name": "è…¾è®¯ç§‘æŠ€", "context": {"industry": "äº’è”ç½‘"}},
            {"name": "é˜¿é‡Œå·´å·´", "context": {"industry": "ç”µå•†"}},
            {"name": "ç™¾åº¦å…¬å¸", "context": {"industry": "æœç´¢"}}
        ]
        
        enhanced_descriptions = batch_processor.batch_enhance_entity_descriptions(entities)
        print(f"æ‰¹é‡å¢å¼ºç»“æœæ•°é‡: {len(enhanced_descriptions)}")
        for i, desc in enumerate(enhanced_descriptions):
            print(f"å®ä½“ {i+1}: {desc}")
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        stats = batch_processor.get_batch_stats()
        print(f"\næ‰¹é‡å¤„ç†å™¨ç»Ÿè®¡: {json.dumps(stats, ensure_ascii=False, indent=2)}")
        
    except Exception as e:
        print(f"æ‰¹é‡å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def test_environment_config():
    """æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®"""
    print("\n=== æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½® ===")
    
    # æ£€æŸ¥å…³é”®ç¯å¢ƒå˜é‡
    env_vars = [
        'LLM_API_KEY',
        'LLM_BASE_URL', 
        'LLM_MODEL',
        'LLM_MAX_TOKENS',
        'LLM_POLLING_PROVIDERS'
    ]
    
    print("å½“å‰ç¯å¢ƒå˜é‡é…ç½®:")
    for var in env_vars:
        value = os.getenv(var, 'æœªè®¾ç½®')
        if var == 'LLM_API_KEY' and value != 'æœªè®¾ç½®':
            # éšè—APIå¯†é’¥çš„éƒ¨åˆ†å†…å®¹
            masked_value = value[:8] + '*' * (len(value) - 12) + value[-4:] if len(value) > 12 else '*' * len(value)
            print(f"{var}: {masked_value}")
        else:
            print(f"{var}: {value}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•æ–°çš„OpenAIå®¢æˆ·ç«¯å’Œè½®è¯¢æ± åŠŸèƒ½...")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®
    test_environment_config()
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("å•ä¸ªå®¢æˆ·ç«¯", test_single_client),
        ("è½®è¯¢æ± ", test_polling_pool),
        ("LLMå¤„ç†å™¨", test_llm_processor),
        ("æ‰¹é‡å¤„ç†å™¨", test_batch_processor)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, success))
            if not success:
                print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
            else:
                print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            results.append((test_name, False))
        
        print("-" * 50)
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    print("\n=== æµ‹è¯•ç»“æœæ€»ç»“ ===")
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    print(f"æ€»æµ‹è¯•æ•°: {total}")
    print(f"é€šè¿‡æ•°: {passed}")
    print(f"å¤±è´¥æ•°: {total - passed}")
    
    for test_name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ–°çš„OpenAIå®¢æˆ·ç«¯å’Œè½®è¯¢æ± åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
        return 0
    else:
        print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œå®ç°ã€‚")
        return 1

if __name__ == "__main__":
    sys.exit(main())