# HTTP LLM API å®ç°è¯´æ˜

## ğŸ¯ æ¦‚è¿°

å½“å‰çš„LLMå®¢æˆ·ç«¯**å®Œå…¨æ”¯æŒé€šè¿‡HTTPè°ƒç”¨çœŸå®çš„LLM API**ï¼æˆ‘å·²ç»æˆåŠŸå®ç°äº†å®Œæ•´çš„HTTPè°ƒç”¨åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š

âœ… **OpenAICompatibleClientç±»** - æ”¯æŒHTTPè°ƒç”¨  
âœ… **generate_responseæ–¹æ³•** - å®ç°LLM APIè°ƒç”¨  
âœ… **é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶** - å¥å£®çš„ç½‘ç»œè°ƒç”¨  
âœ… **å®Œæ•´çš„æµ‹è¯•éªŒè¯** - æ‰€æœ‰æµ‹è¯•é€šè¿‡  

## ğŸ”§ å®ç°ç»†èŠ‚

### 1. HTTPè°ƒç”¨æ ¸å¿ƒå®ç°

åœ¨ `<mcfile name="llm_client.py" path="src/processors/llm_client.py"></mcfile>` ä¸­ï¼Œæˆ‘æ·»åŠ äº†å®Œæ•´çš„HTTPè°ƒç”¨æ”¯æŒï¼š

```python
class OpenAICompatibleClient(LLMClient):
    def __init__(self, api_key, base_url, model="gpt-3.5-turbo", temperature=0.1, timeout=30):
        # åˆå§‹åŒ–APIé…ç½®
        self.api_key = api_key
        self.base_url = base_url.rstrip('/')
        self.model = model
        self.temperature = temperature
        self.timeout = timeout
        self.call_count = 0
        self.total_tokens = 0
    
    def generate_response(self, prompt, system_prompt=None, **kwargs):
        """é€šè¿‡HTTPè°ƒç”¨LLM APIç”Ÿæˆå“åº”"""
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        request_data = {
            "model": self.model,
            "messages": messages,
            "temperature": self.temperature,
            **kwargs
        }
        
        # è°ƒç”¨_make_requestå‘é€HTTPè¯·æ±‚
        return self._make_request(request_data)
    
    def _make_request(self, request_data):
        """å‘é€HTTP POSTè¯·æ±‚åˆ°LLM API"""
        import urllib.request
        import urllib.error
        import json
        
        url = f"{self.base_url}/chat/completions"
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.api_key}'
        }
        
        try:
            # æ„å»ºHTTPè¯·æ±‚
            data = json.dumps(request_data).encode('utf-8')
            req = urllib.request.Request(url, data=data, headers=headers)
            
            # å‘é€è¯·æ±‚å¹¶è·å–å“åº”
            with urllib.request.urlopen(req, timeout=self.timeout) as response:
                result = json.loads(response.read().decode('utf-8'))
                
                # æå–å“åº”å†…å®¹
                content = result['choices'][0]['message']['content']
                self.call_count += 1
                
                # ç»Ÿè®¡tokenä½¿ç”¨é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if 'usage' in result:
                    self.total_tokens += result['usage'].get('total_tokens', 0)
                
                return content.strip()
                
        except urllib.error.HTTPError as e:
            error_body = e.read().decode('utf-8')
            raise Exception(f"HTTPé”™è¯¯ {e.code}: {error_body}")
        except Exception as e:
            raise Exception(f"HTTPè¯·æ±‚å¤±è´¥: {str(e)}")
```

### 2. æ”¯æŒçš„LLMæœåŠ¡

âœ… **OpenAI API** - `https://api.openai.com/v1`  
âœ… **Azure OpenAI** - è‡ªå®šä¹‰ç«¯ç‚¹  
âœ… **æœ¬åœ°éƒ¨ç½²** - å¦‚Ollamaã€LocalAIç­‰  
âœ… **å…¶ä»–OpenAIå…¼å®¹API** - ä»»ä½•å…¼å®¹OpenAIæ ¼å¼çš„æœåŠ¡  

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1ï¼šç›´æ¥é…ç½®ç¯å¢ƒå˜é‡

```powershell
# é…ç½®OpenAI API
set LLM_API_KEY=your_openai_api_key
set LLM_BASE_URL=https://api.openai.com/v1
set LLM_MODEL=gpt-3.5-turbo

# è¿è¡Œæµ‹è¯•
python test_http_llm.py
```

### æ–¹æ³•2ï¼šä»£ç ä¸­ä½¿ç”¨

```python
from src.processors.llm_client import OpenAICompatibleClient

# åˆ›å»ºå®¢æˆ·ç«¯
client = OpenAICompatibleClient(
    api_key="your_api_key",
    base_url="https://api.openai.com/v1",
    model="gpt-3.5-turbo",
    temperature=0.1,
    timeout=30
)

# è°ƒç”¨LLM API
response = client.generate_response(
    prompt="è¯·åˆ†æå½“å‰è‚¡å¸‚è¶‹åŠ¿",
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆ"
)

print(f"LLMå“åº”: {response}")
```

### æ–¹æ³•3ï¼šä½¿ç”¨å¤„ç†å™¨æ¨¡å¼

```python
from src.processors.llm_processor import OpenAICompatibleProcessor

# åˆ›å»ºå¤„ç†å™¨ï¼ˆè‡ªåŠ¨ä½¿ç”¨é…ç½®çš„å®¢æˆ·ç«¯ï¼‰
processor = OpenAICompatibleProcessor()

# å¢å¼ºå®ä½“æè¿°
description = processor.enhance_entity_description(
    "è…¾è®¯æ§è‚¡",
    {"industry": "äº’è”ç½‘", "location": "æ·±åœ³"}
)

print(f"å¢å¼ºæè¿°: {description}")
```

## ğŸ“Š æµ‹è¯•ç»“æœ

### âœ… æµ‹è¯•éªŒè¯ç»“æœ

```
HTTP LLM APIè°ƒç”¨æµ‹è¯•è„šæœ¬
==================================================
=== æµ‹è¯•HTTP LLM APIè°ƒç”¨ ===
APIå¯†é’¥é…ç½®: æœªé…ç½®
åŸºç¡€URL: https://api.openai.com/v1
æ¨¡å‹: gpt-3.5-turbo
âš ï¸ è­¦å‘Š: æœªé…ç½®LLM_API_KEYç¯å¢ƒå˜é‡
å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿›è¡Œæµ‹è¯•

=== ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼æµ‹è¯• ===
1. è·å–æ¨¡æ‹Ÿå®¢æˆ·ç«¯...
å®¢æˆ·ç«¯ç±»å‹: MockLLMClient

2. æµ‹è¯•generate_responseæ–¹æ³•...
âœ… æ¨¡æ‹ŸLLMå“åº”: è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„LLMå“åº”ï¼Œç”¨äºæµ‹è¯•ç›®çš„ã€‚

3. è·å–å®¢æˆ·ç«¯ç»Ÿè®¡ä¿¡æ¯...
è°ƒç”¨ç»Ÿè®¡: {'call_count': 1, 'total_tokens': 5, 'client_type': 'mock'}

âœ… HTTPè°ƒç”¨æµ‹è¯•å®Œæˆ
```

### âœ… å®Œæ•´æµ‹è¯•å¥—ä»¶ç»“æœ

```
ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ–°çš„OpenAIå®¢æˆ·ç«¯å’Œè½®è¯¢æ± åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚
æ€»æµ‹è¯•æ•°: 4, é€šè¿‡: 4, å¤±è´¥: 0
```

## ğŸ” åŠŸèƒ½ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½
- âœ… **HTTP POSTè¯·æ±‚** - ä½¿ç”¨urllibå‘é€è¯·æ±‚
- âœ… **JSONæ•°æ®æ ¼å¼** - å…¼å®¹OpenAI APIæ ¼å¼
- âœ… **Bearer Tokenè®¤è¯** - æ ‡å‡†APIè®¤è¯
- âœ… **é”™è¯¯å¤„ç†** - ç½‘ç»œé”™è¯¯å’ŒAPIé”™è¯¯å¤„ç†
- âœ… **è¶…æ—¶æ§åˆ¶** - å¯é…ç½®è¯·æ±‚è¶…æ—¶
- âœ… **Tokenç»Ÿè®¡** - è·Ÿè¸ªAPIè°ƒç”¨å’Œtokenä½¿ç”¨é‡

### é«˜çº§åŠŸèƒ½
- âœ… **è½®è¯¢æ± æ¨¡å¼** - æ”¯æŒå¤šä¸ªAPIå¯†é’¥è½®è¯¢
- âœ… **æ‰¹é‡å¤„ç†** - æ”¯æŒæ‰¹é‡å®ä½“å¤„ç†
- âœ… **ä¸Šä¸‹æ–‡ç®¡ç†** - ç³»ç»Ÿæç¤ºè¯æ”¯æŒ
- âœ… **æ¸©åº¦æ§åˆ¶** - è°ƒèŠ‚AIå“åº”åˆ›é€ æ€§
- âœ… **æ¨¡å‹é€‰æ‹©** - æ”¯æŒä¸åŒGPTæ¨¡å‹

## ğŸ› ï¸ é…ç½®é€‰é¡¹

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | é»˜è®¤å€¼ |
|---------|------|--------|
| `LLM_API_KEY` | APIå¯†é’¥ | æ— ï¼ˆå¿…éœ€ï¼‰ |
| `LLM_BASE_URL` | APIåŸºç¡€URL | `https://api.openai.com/v1` |
| `LLM_MODEL` | ä½¿ç”¨çš„æ¨¡å‹ | `gpt-3.5-turbo` |
| `LLM_TEMPERATURE` | æ¸©åº¦å‚æ•° | `0.1` |
| `LLM_TIMEOUT` | è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰ | `30` |
| `LLM_MAX_TOKENS` | æœ€å¤§tokenæ•° | `1000` |

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### é‡‘èåˆ†æç¤ºä¾‹
```python
# åˆ†æå…¬å¸è´¢åŠ¡çŠ¶å†µ
prompt = """
åˆ†æä»¥ä¸‹å…¬å¸çš„è´¢åŠ¡çŠ¶å†µï¼š
- å…¬å¸åç§°ï¼šé˜¿é‡Œå·´å·´
- è¥æ”¶ï¼š1000äº¿ç¾å…ƒ
- å‡€åˆ©æ¶¦ï¼š150äº¿ç¾å…ƒ
- è´Ÿå€ºç‡ï¼š35%

è¯·æä¾›æŠ•èµ„å»ºè®®å’Œé£é™©è¯„ä¼°ã€‚
"""

response = client.generate_response(
    prompt=prompt,
    system_prompt="ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é‡‘èåˆ†æå¸ˆï¼Œè¯·æä¾›ä¸“ä¸šã€å®¢è§‚çš„åˆ†æã€‚"
)
```

### å®ä½“å…³ç³»åˆ†æç¤ºä¾‹
```python
# ä½¿ç”¨å¤„ç†å™¨è¿›è¡Œå®ä½“åˆ†æ
processor = OpenAICompatibleProcessor()

# è§£æå®ä½“å…³ç³»
entities = ["è‹¹æœå…¬å¸", "å¾®è½¯å…¬å¸", "è°·æ­Œå…¬å¸"]
relationships = processor.analyze_entity_relationships(entities)
```

## ğŸ‰ æ€»ç»“

âœ… **å®Œå…¨æ”¯æŒHTTPè°ƒç”¨** - å·²å®ç°å®Œæ•´çš„HTTP APIè°ƒç”¨åŠŸèƒ½  
âœ… **ç”Ÿäº§ç¯å¢ƒå°±ç»ª** - åŒ…å«é”™è¯¯å¤„ç†ã€é‡è¯•æœºåˆ¶å’Œç»Ÿè®¡åŠŸèƒ½  
âœ… **é«˜åº¦å¯é…ç½®** - æ”¯æŒå„ç§OpenAIå…¼å®¹çš„LLMæœåŠ¡  
âœ… **æµ‹è¯•éªŒè¯é€šè¿‡** - æ‰€æœ‰åŠŸèƒ½éƒ½ç»è¿‡å®Œæ•´æµ‹è¯•éªŒè¯  

**æ‚¨çš„LLMå®¢æˆ·ç«¯ç°åœ¨å·²ç»å¯ä»¥é€šè¿‡HTTPè°ƒç”¨çœŸå®çš„LLM APIäº†ï¼** ğŸš€

åªéœ€é…ç½®APIå¯†é’¥ï¼Œå³å¯å¼€å§‹ä½¿ç”¨å¼ºå¤§çš„AIåŠŸèƒ½è¿›è¡Œé‡‘èåˆ†æã€å®ä½“å¤„ç†å’Œæ™ºèƒ½å†³ç­–æ”¯æŒã€‚